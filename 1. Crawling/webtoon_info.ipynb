{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹툰 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "f = open('webtoon_info.csv','w')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['코드' ,'제목', '점수', '작가', '장르' , '추가 정보', '첫 회 링크'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "def get_week(soup) :\n",
    "    # 요일별 전체 웹툰 가져오기\n",
    "    title = soup.select('.title')\n",
    "    t_weekdays = list(map(lambda x: x.get('href').split('weekday=')[1], title))\n",
    "\n",
    "    new_week = []\n",
    "    for v in t_weekdays:\n",
    "        if v not in new_week:\n",
    "            new_week.append(v)\n",
    "            \n",
    "#     print(new_week)\n",
    "    return(new_week)\n",
    "\n",
    "def main():\n",
    "    list_href = []\n",
    "\n",
    "    url = \"https://comic.naver.com/webtoon/weekday.nhn\"\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, \"html.parser\")\n",
    "\n",
    "    # 요일 가져오기\n",
    "    week = get_week(soup)\n",
    "    \n",
    "    #웹툰별 스코어\n",
    "    score_info = get_score(week)\n",
    "\n",
    "    \n",
    "    #웹툰 코드와 제목\n",
    "    code_title = get_code(soup)\n",
    "    \n",
    "    # 코드만 분류\n",
    "    code = list(code_title.keys())\n",
    "\n",
    "    \n",
    "    # 코드 ,제목, 점수, 작가, 장르 , 추가 정보, 첫회 링크\n",
    "    for c in code:\n",
    "      wr.writerow([c,code_title[c], score_info[c], get_writer(c), get_genre(c), get_detail(c), get_first_url(c)])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()# 요일별 전체 웹툰 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드따오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(soup):\n",
    "    title = soup.select('.title')\n",
    "    \n",
    "    # 웹툰 코드, 요일별, 웹툰 제목\n",
    "    t_Code=list(map(lambda x: x.get('href').split('titleId=')[1].split('&')[0], title))\n",
    "    t_weekdays = list(map(lambda x: x.get('href').split('weekday=')[1], title))\n",
    "    t_names = list(map(lambda x: x.text ,title))\n",
    "    \n",
    "    \n",
    "    # data = {웹툰 코드 : 웹툰 제목}\n",
    "    data ={}\n",
    "    for i in range(len(t_Code)):\n",
    "        data[t_Code[i]] =t_names[i]\n",
    "        \n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평점가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(week_list):\n",
    "    score_data = {}\n",
    "    for week in week_list:\n",
    "        score_url = \"https://comic.naver.com/webtoon/weekdayList.nhn?week=\" + week\n",
    "        score_req = requests.get(score_url)\n",
    "        score_soup = BeautifulSoup(score_req.text, \"html.parser\")\n",
    "\n",
    "        title_info = score_soup.select('ul.img_list > li > dl > dt > a')\n",
    "        t_code=list(map(lambda x: x.get('href').split('titleId=')[1].split('&')[0], title_info))\n",
    "#         print(t_IDs)\n",
    "\n",
    "        score_info = score_soup.select('div.rating_type > strong')\n",
    "        t_score = list(map(lambda x: x.text ,score_info))\n",
    "#         print(t_score)\n",
    "    \n",
    "        for i in range(len(t_code)):\n",
    "            score_data[t_code[i]]= t_score[i]\n",
    "    \n",
    "\n",
    "#     print(score_data)\n",
    "    return(score_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 작가 이름들, 소개글, 첫회가기, 장르"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_writer(code):\n",
    "    wt_url = (\"https://comic.naver.com/webtoon/list.nhn?titleId=\"+str(code))\n",
    "    req = requests.get(wt_url)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "    # print(soup)\n",
    "\n",
    "    web_info= soup.select('div.comicinfo')\n",
    "\n",
    "    writer = ''\n",
    "    \n",
    "\n",
    "    for info in web_info:\n",
    "        \n",
    "        detail_tag = info.select_one('div.detail')\n",
    "        name = info.select_one('h2 > span.wrt_nm').text\n",
    "        \n",
    "        writer = name.strip()\n",
    "\n",
    "\n",
    "    \n",
    "    return(writer)\n",
    "\n",
    "\n",
    "\n",
    "def get_genre(code):\n",
    "    wt_url = (\"https://comic.naver.com/webtoon/list.nhn?titleId=\"+str(code))\n",
    "    req = requests.get(wt_url)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "    # print(soup)\n",
    "\n",
    "    web_info= soup.select('div.comicinfo')\n",
    "    # print(web_info)\n",
    "    genre = ''\n",
    "    for info in web_info:\n",
    "        \n",
    "        detail_tag = info.select_one('div.detail')\n",
    "        genre = detail_tag.select_one('p.detail_info > span.genre').text\n",
    "\n",
    "    return(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detail(code):\n",
    "    wt_url = (\"https://comic.naver.com/webtoon/list.nhn?titleId=\"+str(code))\n",
    "    req = requests.get(wt_url)\n",
    "    soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    web_info= soup.select('div.comicinfo')\n",
    "    \n",
    "    detail = ''\n",
    "    \n",
    "    webtoon_info = []\n",
    "    for info in web_info:\n",
    "        \n",
    "        detail_tag = info.select_one('div.detail')        \n",
    "        detail = detail_tag.find('p').text\n",
    "\n",
    "    \n",
    "    \n",
    "    return(detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_url(code):\n",
    "\n",
    "    \n",
    "    first_url = 'https://comic.naver.com/webtoon/detail.nhn?titleId='+str(code)+'&no=1'\n",
    "    \n",
    "    \n",
    "    return(first_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
